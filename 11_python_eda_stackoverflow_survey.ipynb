{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubenMcCarty/Data-Analysis-Python/blob/main/11_python_eda_stackoverflow_survey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUffRwobna8Q"
      },
      "source": [
        "# Exploratory Data Analysis using Python - A Case Study\n",
        "\n",
        "*Analyzing responses from the Stack Overflow Annual Developer Survey 2020*\n",
        "## [MSc:Ruben Quispe](https://www.linkedin.com/in/msc-rub%C3%A9n-quispe-l/)\n",
        "![](https://i.imgur.com/qXhHKqv.png)\n",
        "\n",
        "### Part 9 of \"Data Analysis with Python: Zero to Pandas\"\n",
        "\n",
        "This tutorial series is a beginner-friendly introduction to programming and data analysis using the Python programming language. These tutorials take a practical and coding-focused approach. The best way to learn the material is to execute the code and experiment with it yourself. Check out the full series here: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkj_Z7gEna8S"
      },
      "source": [
        "The following topics are covered in this tutorial:\n",
        "\n",
        "- Selecting and downloading a dataset\n",
        "- Data preparation and cleaning\n",
        "- Exploratory analysis and visualization\n",
        "- Asking and answering interesting questions\n",
        "- Summarizing inferences and drawing conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl6-BXW0na8T"
      },
      "source": [
        "### How to run the code\n",
        "\n",
        "This tutorial is an executable [Jupyter notebook](https://jupyter.org) . You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
        "\n",
        "#### Option 1: Running using free online resources (1-click, recommended)\n",
        "\n",
        "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.\n",
        "\n",
        "\n",
        "#### Option 2: Running on your computer locally\n",
        "\n",
        "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
        "\n",
        ">  **Jupyter Notebooks**: This tutorial is a [Jupyter notebook](https://jupyter.org) - a document made of _cells_. Each cell can contain code written in Python or explanations in plain English. You can execute code cells and view the results, e.g., numbers, messages, graphs, tables, files, etc., instantly within the notebook. Jupyter is a powerful platform for experimentation and analysis. Don't be afraid to mess around with the code & break things - you'll learn a lot by encountering and fixing errors. You can use the \"Kernel > Restart & Clear Output\" menu option to clear all outputs and start again from the top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rBN3ky-na8T"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we'll analyze the StackOverflow developer survey dataset. The dataset contains responses to an annual survey conducted by StackOverflow. You can find the raw data & official analysis here: https://insights.stackoverflow.com/survey.\n",
        "\n",
        "There are several options for getting the dataset into Jupyter:\n",
        "\n",
        "- Download the CSV manually and upload it via Jupyter's GUI\n",
        "- Use the `urlretrieve` function from the `urllib.request` to download CSV files from a raw URL\n",
        "- Use a helper library, e.g., [`opendatasets`](https://github.com/JovianML/opendatasets), which contains a collection of curated datasets and provides a helper function for direct download.\n",
        "\n",
        "We'll use the `opendatasets` helper library to download the files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-sdk[opendatasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nkXlhTCn-X8",
        "outputId": "824f05b3-f1c0-4a57-9b2b-f7a7a5076644"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting azureml-sdk[opendatasets]\n",
            "  Downloading azureml_sdk-1.46.0-py3-none-any.whl (2.7 kB)\n",
            "\u001b[33mWARNING: azureml-sdk 1.46.0 does not provide the extra 'opendatasets'\u001b[0m\n",
            "Collecting azureml-train-automl-client~=1.46.0\n",
            "  Downloading azureml_train_automl_client-1.46.0-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting azureml-train-core~=1.46.0\n",
            "  Downloading azureml_train_core-1.46.0-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 20.5 MB/s \n",
            "\u001b[?25hCollecting azureml-pipeline~=1.46.0\n",
            "  Downloading azureml_pipeline-1.46.0-py3-none-any.whl (2.4 kB)\n",
            "Collecting azureml-core~=1.46.0\n",
            "  Downloading azureml_core-1.46.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting azureml-dataset-runtime[fuse]~=1.46.0\n",
            "  Downloading azureml_dataset_runtime-1.46.0-py3-none-any.whl (2.3 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 36.7 MB/s \n",
            "\u001b[?25hCollecting pkginfo\n",
            "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
            "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.10.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2.23.0)\n",
            "Collecting azure-mgmt-authorization<3,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 58.0 MB/s \n",
            "\u001b[?25hCollecting docker<6.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 40.1 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n",
            "  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 65.4 MB/s \n",
            "\u001b[?25hCollecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging<22.0,>=20.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (21.3)\n",
            "Collecting pyopenssl<23.0.0\n",
            "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting msrest<=0.7.1,>=0.5.1\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting humanfriendly<11.0,>=4.7\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting argcomplete<3\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: contextlib2<22.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (0.5.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2022.4)\n",
            "Collecting knack~=0.9.0\n",
            "  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
            "Collecting paramiko<3.0.0,>=2.0.8\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n",
            "  Downloading azure_mgmt_resource-21.2.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 48.0 MB/s \n",
            "\u001b[?25hCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.0.0,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (1.24.3)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-10.1.0-py3-none-any.whl (605 kB)\n",
            "\u001b[K     |████████████████████████████████| 605 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting msal<2.0.0,>=1.15.0\n",
            "  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0\n",
            "  Downloading azure_core-1.26.0-py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2.8.2)\n",
            "Collecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
            "  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete<3->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (4.1.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (1.15.0)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\n",
            "Collecting azureml-dataprep<4.6.0a,>=4.5.0a\n",
            "  Downloading azureml_dataprep-4.5.7-py3-none-any.whl (43.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 43.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.19.3 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (1.21.6)\n",
            "Requirement already satisfied: pyarrow<=9.0.0,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (6.0.1)\n",
            "Collecting fusepy<4.0.0,>=3.0.1\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting azure-identity==1.7.0\n",
            "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting azureml-dataprep-rslex~=2.11.0dev0\n",
            "  Downloading azureml_dataprep_rslex-2.11.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 133 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (1.5.0)\n",
            "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
            "  Downloading azureml_dataprep_native-38.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (6.0)\n",
            "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
            "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (4.3.3)\n",
            "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
            "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting azureml-pipeline-steps~=1.46.0\n",
            "  Downloading azureml_pipeline_steps-1.46.0-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting azureml-pipeline-core~=1.46.0\n",
            "  Downloading azureml_pipeline_core-1.46.0-py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting azureml-telemetry~=1.46.0\n",
            "  Downloading azureml_telemetry-1.46.0-py3-none-any.whl (30 kB)\n",
            "Collecting azureml-automl-core~=1.46.0\n",
            "  Downloading azureml_automl_core-1.46.1.post1-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting applicationinsights\n",
            "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting azureml-train-restclients-hyperdrive~=1.46.0\n",
            "  Downloading azureml_train_restclients_hyperdrive-1.46.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2.21)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting distro>=1.2.0\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<3->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (3.9.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (0.8.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2.6.1)\n",
            "Collecting portalocker<3,>=1.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 632 kB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2022.9.24)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=20.0->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (3.0.9)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 57.4 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 61.1 MB/s \n",
            "\u001b[?25hCollecting pyopenssl<23.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (3.2.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-sdk[opendatasets]) (1.7.1)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse]~=1.46.0->azureml-sdk[opendatasets]) (5.10.0)\n",
            "Building wheels for collected packages: fusepy\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=5240ec48729b556866aa4dedf4662a2331fbff4c36754ba8ab8985fa33b3b363\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\n",
            "Successfully built fusepy\n",
            "Installing collected packages: PyJWT, cryptography, isodate, azure-core, portalocker, msrest, msal, adal, websocket-client, pyopenssl, pynacl, msrestazure, msal-extensions, jmespath, jeepney, distro, bcrypt, backports.weakref, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, ndg-httpsclient, knack, jsonpickle, humanfriendly, dotnetcore2, docker, backports.tempfile, azureml-dataprep-rslex, azureml-dataprep-native, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-identity, azure-graphrbac, azureml-dataprep, azureml-core, applicationinsights, azureml-train-restclients-hyperdrive, azureml-telemetry, azureml-dataset-runtime, azureml-train-core, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-core, fusepy, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n",
            "Successfully installed PyJWT-2.6.0 SecretStorage-3.3.3 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 azure-common-1.1.28 azure-core-1.26.0 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.1.0 azure-mgmt-resource-21.2.1 azure-mgmt-storage-20.0.0 azureml-automl-core-1.46.1.post1 azureml-core-1.46.0 azureml-dataprep-4.5.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.11.4 azureml-dataset-runtime-1.46.0 azureml-pipeline-1.46.0 azureml-pipeline-core-1.46.0 azureml-pipeline-steps-1.46.0 azureml-sdk-1.46.0 azureml-telemetry-1.46.0 azureml-train-automl-client-1.46.0 azureml-train-core-1.46.0 azureml-train-restclients-hyperdrive-1.46.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cryptography-37.0.4 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 fusepy-3.0.1 humanfriendly-10.0 isodate-0.6.1 jeepney-0.8.0 jmespath-1.0.1 jsonpickle-2.2.0 knack-0.9.0 msal-1.20.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 paramiko-2.11.0 pathspec-0.10.1 pkginfo-1.8.3 portalocker-2.6.0 pynacl-1.5.0 pyopenssl-22.0.0 websocket-client-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azureml-opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld-0c9w9duUK",
        "outputId": "4595b2be-0b82-468b-817d-c6c4a340f621"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting azureml-opendatasets\n",
            "  Downloading azureml_opendatasets-1.46.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<=2.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.21.6)\n",
            "Requirement already satisfied: azureml-telemetry~=1.46.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.46.0)\n",
            "Requirement already satisfied: pandas<=2.0.0,>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.3.5)\n",
            "Requirement already satisfied: azureml-core~=1.46.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.46.0)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (6.0.1)\n",
            "Requirement already satisfied: scipy<=2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.7.3)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 44 kB/s \n",
            "\u001b[?25hRequirement already satisfied: azureml-dataset-runtime[fuse,pandas]~=1.46.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.46.0)\n",
            "Requirement already satisfied: knack~=0.9.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.9.0)\n",
            "Requirement already satisfied: SecretStorage<4.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (3.3.3)\n",
            "Requirement already satisfied: azure-mgmt-storage<=20.0.0,>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (20.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2022.4)\n",
            "Requirement already satisfied: humanfriendly<11.0,>=4.7 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (10.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.24.3)\n",
            "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.2.7)\n",
            "Requirement already satisfied: jsonpickle<3.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.2.0)\n",
            "Requirement already satisfied: ndg-httpsclient<=0.5.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.5.1)\n",
            "Requirement already satisfied: azure-mgmt-resource<22.0.0,>=15.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (21.2.1)\n",
            "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.23.0)\n",
            "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (10.1.0)\n",
            "Requirement already satisfied: contextlib2<22.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.5.5)\n",
            "Requirement already satisfied: PyJWT<3.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.6.0)\n",
            "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.1.28)\n",
            "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (10.0.0)\n",
            "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.6.4)\n",
            "Requirement already satisfied: pathspec<1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.10.1)\n",
            "Requirement already satisfied: jmespath<2.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.0.1)\n",
            "Requirement already satisfied: msal-extensions<=1.0.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.3.1)\n",
            "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.61.1)\n",
            "Requirement already satisfied: packaging<22.0,>=20.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (21.3)\n",
            "Requirement already satisfied: azure-mgmt-authorization<3,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.0.0)\n",
            "Requirement already satisfied: msal<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.20.0)\n",
            "Requirement already satisfied: pyopenssl<23.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (22.0.0)\n",
            "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (0.7.1)\n",
            "Requirement already satisfied: argcomplete<3 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.0.0)\n",
            "Requirement already satisfied: backports.tempfile in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.0)\n",
            "Requirement already satisfied: paramiko<3.0.0,>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.11.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (2.8.2)\n",
            "Requirement already satisfied: azure-core<2.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.26.0)\n",
            "Requirement already satisfied: pkginfo in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (1.8.3)\n",
            "Requirement already satisfied: docker<6.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (5.0.3)\n",
            "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.46.0->azureml-opendatasets) (37.0.4)\n",
            "Requirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete<3->azureml-core~=1.46.0->azureml-opendatasets) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0->azureml-core~=1.46.0->azureml-opendatasets) (4.1.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0->azureml-core~=1.46.0->azureml-opendatasets) (1.15.0)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from azure-mgmt-authorization<3,>=0.40.0->azureml-core~=1.46.0->azureml-opendatasets) (1.3.2)\n",
            "Requirement already satisfied: azureml-dataprep<4.6.0a,>=4.5.0a in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (4.5.7)\n",
            "Requirement already satisfied: fusepy<4.0.0,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (3.0.1)\n",
            "Requirement already satisfied: azureml-dataprep-rslex~=2.11.0dev0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (6.0)\n",
            "Requirement already satisfied: azure-identity==1.7.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (1.7.0)\n",
            "Requirement already satisfied: dotnetcore2<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (3.1.23)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (4.3.3)\n",
            "Requirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (1.5.0)\n",
            "Requirement already satisfied: azureml-dataprep-native<39.0.0,>=38.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (38.0.0)\n",
            "Requirement already satisfied: applicationinsights in /usr/local/lib/python3.7/dist-packages (from azureml-telemetry~=1.46.0->azureml-opendatasets) (0.11.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0->azureml-core~=1.46.0->azureml-opendatasets) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0->azureml-core~=1.46.0->azureml-opendatasets) (2.21)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker<6.0.0->azureml-core~=1.46.0->azureml-opendatasets) (1.4.1)\n",
            "Requirement already satisfied: distro>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from dotnetcore2<4.0.0,>=3.0.0->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (1.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<3->azureml-core~=1.46.0->azureml-opendatasets) (3.9.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core~=1.46.0->azureml-opendatasets) (0.8.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core~=1.46.0->azureml-opendatasets) (2.6.1)\n",
            "Requirement already satisfied: portalocker<3,>=1.0 in /usr/local/lib/python3.7/dist-packages (from msal-extensions<=1.0.0,>=0.3.0->azureml-core~=1.46.0->azureml-opendatasets) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-opendatasets) (2022.9.24)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-opendatasets) (1.3.1)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-opendatasets) (0.6.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.46.0->azureml-opendatasets) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=20.0->azureml-core~=1.46.0->azureml-opendatasets) (3.0.9)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko<3.0.0,>=2.0.8->azureml-core~=1.46.0->azureml-opendatasets) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko<3.0.0,>=2.0.8->azureml-core~=1.46.0->azureml-opendatasets) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-opendatasets) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.46.0->azureml-opendatasets) (3.2.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.46.0->azureml-opendatasets) (1.7.1)\n",
            "Requirement already satisfied: jeepney>=0.6 in /usr/local/lib/python3.7/dist-packages (from SecretStorage<4.0.0->azureml-core~=1.46.0->azureml-opendatasets) (0.8.0)\n",
            "Requirement already satisfied: backports.weakref in /usr/local/lib/python3.7/dist-packages (from backports.tempfile->azureml-core~=1.46.0->azureml-opendatasets) (1.0.post1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (5.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->azureml-dataprep<4.6.0a,>=4.5.0a->azureml-dataset-runtime[fuse,pandas]~=1.46.0->azureml-opendatasets) (0.18.1)\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 49.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=d4765e1634e779479a2d9ed90bad53fafd0b1d1a1c11871606eb418b1b3bb42e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark, azureml-opendatasets\n",
            "Successfully installed azureml-opendatasets-1.46.0 py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "E91J1BtGna8T",
        "outputId": "c92dc0d4-0e26-4dfb-c306-8c6f7dd9ebc6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d93a2fe27d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopendatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opendatasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ygFnTuna8U"
      },
      "outputs": [],
      "source": [
        "od.download('stackoverflow-developer-survey-2020')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBbMSArpna8U"
      },
      "source": [
        "Let's verify that the dataset was downloaded into the directory `stackoverflow-developer-survey-2020` and retrieve the list of files in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tz1uM1Pna8V"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Vd6uJGYhna8V"
      },
      "outputs": [],
      "source": [
        "os.listdir('stackoverflow-developer-survey-2020')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1-fNzYbna8V"
      },
      "source": [
        "You can through the downloaded files using the \"File\" > \"Open\" menu option in Jupyter. It seems like the dataset contains three files:\n",
        "\n",
        "- `README.txt` - Information about the dataset\n",
        "- `survey_results_schema.csv` - The list of questions, and shortcodes for each question\n",
        "- `survey_results_public.csv` - The full list of responses to the questions \n",
        "\n",
        "Let's load the CSV files using the Pandas library. We'll use the name `survey_raw_df` for the data frame to indicate this is unprocessed data that we might clean, filter, and modify to prepare a data frame ready for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxnxfWs3na8V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMUx0z2xna8W"
      },
      "outputs": [],
      "source": [
        "survey_raw_df = pd.read_csv('stackoverflow-developer-survey-2020/survey_results_public.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592kahIVna8W"
      },
      "outputs": [],
      "source": [
        "survey_raw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K2MjQzKna8W"
      },
      "source": [
        "The dataset contains over 64,000 responses to 60 questions (although many questions are optional). The responses have been anonymized to remove personally identifiable information, and each respondent has been assigned a randomized respondent ID.\n",
        "\n",
        "Let's view the list of columns in the data frame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaQyZEvvna8W"
      },
      "outputs": [],
      "source": [
        "survey_raw_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iehIMUGna8W"
      },
      "source": [
        "It appears that shortcodes for questions have been used as column names. \n",
        "\n",
        "We can refer to the schema file to see the full text of each question. The schema file contains only two columns: `Column` and `QuestionText`. We can load it as Pandas Series with `Column` as the index and the  `QuestionText` as the value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy9uwAl7na8W"
      },
      "outputs": [],
      "source": [
        "schema_fname = 'stackoverflow-developer-survey-2020/survey_results_schema.csv'\n",
        "schema_raw = pd.read_csv(schema_fname, index_col='Column').QuestionText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmUpKoz6na8W"
      },
      "outputs": [],
      "source": [
        "schema_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o732f1W6na8X"
      },
      "source": [
        "We can now use `schema_raw` to retrieve the full question text for any column in `survey_raw_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1fJWAhCna8X"
      },
      "outputs": [],
      "source": [
        "schema_raw['YearsCodePro']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Ppd5yOna8X"
      },
      "source": [
        "We've now loaded the dataset. We're ready to move on to the next step of preprocessing & cleaning the data for our analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMhHa2RFna8X"
      },
      "source": [
        "### Save and upload your notebook\n",
        "\n",
        "Whether you're running this Jupyter notebook online or on your computer, it's essential to save your work from time to time. You can continue working on a saved notebook later or share it with friends and colleagues to let them execute your code. [Jovian](https://www.jovian.ai) offers an easy way of saving and sharing your Jupyter notebooks online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYxWUJstna8X"
      },
      "outputs": [],
      "source": [
        "# Select a project name\n",
        "project='python-eda-stackoverflow-survey'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG1cLkgHna8X"
      },
      "outputs": [],
      "source": [
        "# Install the Jovian library\n",
        "!pip install jovian --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsfpAKlmna8X"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYiTIpWnna8X"
      },
      "outputs": [],
      "source": [
        "jovian.commit(project=project)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoG6nfwPna8X"
      },
      "source": [
        "The first time you run `jovian.commit`, you'll be asked to provide an API Key to securely upload the notebook to your Jovian account. You can get the API key from your [Jovian profile page](https://jovian.ai) after logging in / signing up.\n",
        "\n",
        "\n",
        "`jovian.commit` uploads the notebook to your Jovian account, captures the Python environment, and creates a shareable link for your notebook, as shown above. You can use this link to share your work and let anyone (including you) run your notebooks and reproduce your work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUbWtVxGna8X"
      },
      "source": [
        "## Data Preparation & Cleaning\n",
        "\n",
        "While the survey responses contain a wealth of information, we'll limit our analysis to the following areas:\n",
        "\n",
        "- Demographics of the survey respondents and the global programming community\n",
        "- Distribution of programming skills, experience, and preferences\n",
        "- Employment-related information, preferences, and opinions\n",
        "\n",
        "Let's select a subset of columns with the relevant data for our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNCZwVYwna8X"
      },
      "outputs": [],
      "source": [
        "selected_columns = [\n",
        "    # Demographics\n",
        "    'Country',\n",
        "    'Age',\n",
        "    'Gender',\n",
        "    'EdLevel',\n",
        "    'UndergradMajor',\n",
        "    # Programming experience\n",
        "    'Hobbyist',\n",
        "    'Age1stCode',\n",
        "    'YearsCode',\n",
        "    'YearsCodePro',\n",
        "    'LanguageWorkedWith',\n",
        "    'LanguageDesireNextYear',\n",
        "    'NEWLearn',\n",
        "    'NEWStuck',\n",
        "    # Employment\n",
        "    'Employment',\n",
        "    'DevType',\n",
        "    'WorkWeekHrs',\n",
        "    'JobSat',\n",
        "    'JobFactors',\n",
        "    'NEWOvertime',\n",
        "    'NEWEdImpt'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7KrS2Ysna8X"
      },
      "outputs": [],
      "source": [
        "len(selected_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbZXRr-Pna8X"
      },
      "source": [
        "Let's extract a copy of the data from these columns into a new data frame `survey_df`. We can continue to modify further without affecting the original data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSTiR5pwna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df = survey_raw_df[selected_columns].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFhmGpFsna8Y"
      },
      "outputs": [],
      "source": [
        "schema = schema_raw[selected_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLOUbkMSna8Y"
      },
      "source": [
        "Let's view some basic information about the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYnaq9c7na8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUIn3zjtna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cREgT00zna8Y"
      },
      "source": [
        "Most columns have the data type `object`, either because they contain values of different types or contain empty values (`NaN`). It appears that every column contains some empty values since the Non-Null count for every column is lower than the total number of rows (64461). We'll need to deal with empty values and manually adjust the data type for each column on a case-by-case basis. \n",
        "\n",
        "Only two of the columns were detected as numeric columns (`Age` and `WorkWeekHrs`), even though a few other columns have mostly numeric values. To make our analysis easier, let's convert some other columns into numeric data types while ignoring any non-numeric value. The non-numeric are converted to `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IskXxuxna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df['Age1stCode'] = pd.to_numeric(survey_df.Age1stCode, errors='coerce')\n",
        "survey_df['YearsCode'] = pd.to_numeric(survey_df.YearsCode, errors='coerce')\n",
        "survey_df['YearsCodePro'] = pd.to_numeric(survey_df.YearsCodePro, errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZtSzQLina8Y"
      },
      "source": [
        "Let's now view some basic statistics about numeric columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XNYMCoLna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtJzPMTRna8Y"
      },
      "source": [
        "There seems to be a problem with the age column, as the minimum value is 1 and the maximum is 279. This is a common issue with surveys: responses may contain invalid values due to accidental or intentional errors while responding. A simple fix would be to ignore the rows where the age is higher than 100 years or lower than 10 years as invalid survey responses. We can do this using the `.drop` method, [as explained here](https://www.geeksforgeeks.org/drop-rows-from-the-dataframe-based-on-certain-condition-applied-on-a-column/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-rPZA5Lna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.drop(survey_df[survey_df.Age < 10].index, inplace=True)\n",
        "survey_df.drop(survey_df[survey_df.Age > 100].index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C0BIagNna8Y"
      },
      "source": [
        "The same holds for `WorkWeekHrs`. Let's ignore entries where the value for the column is higher than 140 hours. (~20 hours per day)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pftlsa9rna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.drop(survey_df[survey_df.WorkWeekHrs > 140].index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdwTu3iFna8Y"
      },
      "source": [
        "The gender column also allows for picking multiple options. We'll remove values containing more than one option to simplify our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whM3MZxsna8Y"
      },
      "outputs": [],
      "source": [
        "survey_df['Gender'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5Xrk7Rsna8Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSXQ-W2Ena8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.where(~(survey_df.Gender.str.contains(';', na=False)), np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvuKrKjlna8Y"
      },
      "source": [
        "We've now cleaned up and prepared the dataset for analysis. Let's take a look at a sample of rows from the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sAzmkB1na8Y"
      },
      "outputs": [],
      "source": [
        "survey_df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSmRlvoWna8Z"
      },
      "source": [
        "Let's save and commit our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB48rrDIna8Z"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPVLPNwdna8Z"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y965S2rena8Z"
      },
      "source": [
        "## Exploratory Analysis and Visualization\n",
        "\n",
        "Before we ask questions about the survey responses, it would help to understand the respondents' demographics, i.e., country, age, gender, education level, employment level, etc. It's essential to explore these variables to understand how representative the survey is of the worldwide programming community. A survey of this scale generally tends to have some [selection bias](https://en.wikipedia.org/wiki/Selection_bias).\n",
        "\n",
        "Let's begin by importing `matplotlib.pyplot` and `seaborn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0MyTEyNna8Z"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (9, 5)\n",
        "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pih0JKDna8Z"
      },
      "source": [
        "### Country\n",
        "\n",
        "Let's look at the number of countries from which there are responses in the survey and plot the ten countries with the highest number of responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0JEP7ypna8Z"
      },
      "outputs": [],
      "source": [
        "schema.Country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-AOWFocna8Z"
      },
      "outputs": [],
      "source": [
        "survey_df.Country.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVme0XX7na8Z"
      },
      "source": [
        "We can identify the countries with the highest number of respondents using the `value_counts` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htu9PF57na8Z"
      },
      "outputs": [],
      "source": [
        "top_countries = survey_df.Country.value_counts().head(15)\n",
        "top_countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE5AKYUFna8Z"
      },
      "source": [
        "We can visualize this information using a bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFANOFMWna8Z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.xticks(rotation=75)\n",
        "plt.title(schema.Country)\n",
        "sns.barplot(x=top_countries.index, y=top_countries);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvRAx0cna8Z"
      },
      "source": [
        "It appears that a disproportionately high number of respondents are from the US and India, probably because the survey is in English, and these countries have the highest English-speaking populations. We can already see that the survey may not be representative of the global programming community - especially from non-English speaking countries. Programmers from non-English speaking countries are almost certainly underrepresented.\n",
        "\n",
        "**Exercise**:\n",
        "Try finding the percentage of responses from English-speaking vs. non-English speaking countries. You can use [this list of languages spoken in different countries](https://github.com/JovianML/opendatasets/blob/master/data/countries-languages-spoken/countries-languages.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRp3NIVina8Z"
      },
      "source": [
        "### Age\n",
        "\n",
        "The distribution of respondents' age is another crucial factor to look at. We can use a histogram to visualize it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByLh0Mc3na8Z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.title(schema.Age)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of respondents')\n",
        "\n",
        "plt.hist(survey_df.Age, bins=np.arange(10,80,5), color='purple');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iuku6funa8Z"
      },
      "source": [
        "It appears that a large percentage of respondents are 20-45 years old. It's somewhat representative of the programming community in general. Many young people have taken up computer science as their field of study or profession in the last 20 years.\n",
        "\n",
        "**Exercise**: You may want to filter out responses by age (or age group) if you'd like to analyze and compare the survey results for different age groups. Create a new column called AgeGroup containing values like `Less than 10 years`, `10-18 years`, `18-30 years`, `30-45 years`, `45-60 years` and `Older than 60 years`. Then, repeat the analysis in the rest of this notebook for each age group.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erf93VuZna8Z"
      },
      "source": [
        "### Gender\n",
        "\n",
        "Let's look at the distribution of responses for the Gender. It's a well-known fact that women and non-binary genders are underrepresented in the programming community, so we might expect to see a skewed distribution here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIukEJLWna8Z"
      },
      "outputs": [],
      "source": [
        "schema.Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhq5DFZena8Z"
      },
      "outputs": [],
      "source": [
        "gender_counts = survey_df.Gender.value_counts()\n",
        "gender_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98z0r-LNna8a"
      },
      "source": [
        "A pie chart would be a great way to visualize the distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3eRvu6-na8a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title(schema.Gender)\n",
        "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=180);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqe6lDRUna8a"
      },
      "source": [
        "Only about 8% of survey respondents who have answered the question identify as women or non-binary. This number is lower than the overall percentage of women & non-binary genders in the programming community - which is estimated to be around 12%. \n",
        "\n",
        "**Exercise**: It would be interesting to compare the survey responses & preferences across genders. Repeat this analysis with these breakdowns. How do the relative education levels differ across genders? How do the salaries vary? You may find this analysis on the [Gender Divide in Data Science](https://medium.com/datadriveninvestor/exploratory-data-analysis-eda-understanding-the-gender-divide-in-data-science-roles-9faa5da44f5b) useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQbPNPk1na8a"
      },
      "source": [
        "### Education Level\n",
        "\n",
        "Formal education in computer science is often considered an essential requirement for becoming a programmer. However, there are many free resources & tutorials available online to learn programming. Let's compare the education levels of respondents to gain some insight into this. We'll use a horizontal bar plot here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPo9g-bgna8a"
      },
      "outputs": [],
      "source": [
        "sns.countplot(y=survey_df.EdLevel)\n",
        "plt.xticks(rotation=75);\n",
        "plt.title(schema['EdLevel'])\n",
        "plt.ylabel(None);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "677UFZWmna8a"
      },
      "source": [
        "It appears that well over half of the respondents hold a bachelor's or master's degree, so most programmers seem to have some college education. However, it's not clear from this graph alone if they hold a degree in computer science.\n",
        "\n",
        "**Exercises**: The graph currently shows the number of respondents for each option. Can you modify it to show the percentage instead? Further, try comparing the percentages for each degree for men vs. women. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRRTGG5Pna8a"
      },
      "source": [
        "Let's also plot undergraduate majors, but this time we'll convert the numbers into percentages and sort the values to make it easier to visualize the order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNla7_O1na8a"
      },
      "outputs": [],
      "source": [
        "schema.UndergradMajor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LJAx648na8a"
      },
      "outputs": [],
      "source": [
        "undergrad_pct = survey_df.UndergradMajor.value_counts() * 100 / survey_df.UndergradMajor.count()\n",
        "\n",
        "sns.barplot(x=undergrad_pct, y=undergrad_pct.index)\n",
        "\n",
        "plt.title(schema.UndergradMajor)\n",
        "plt.ylabel(None);\n",
        "plt.xlabel('Percentage');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjO035TNna8a"
      },
      "source": [
        "It turns out that 40% of programmers holding a college degree have a field of study other than computer science - which is very encouraging. It seems to suggest that while a college education is helpful in general, you do not need to pursue a major in computer science to become a successful programmer.\n",
        "\n",
        "**Exercises**: Analyze the `NEWEdImpt` column for respondents who hold some college degree vs. those who don't. Do you notice any difference in opinion?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0LxyUOWna8a"
      },
      "source": [
        "### Employment\n",
        "\n",
        "Freelancing or contract work is a common choice among programmers, so it would be interesting to compare the breakdown between full-time, part-time, and freelance work. Let's visualize the data from the `Employment` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9mXE8Mzna8a"
      },
      "outputs": [],
      "source": [
        "schema.Employment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXyIirAUna8a"
      },
      "outputs": [],
      "source": [
        "(survey_df.Employment.value_counts(normalize=True, ascending=True)*100).plot(kind='barh', color='g')\n",
        "plt.title(schema.Employment)\n",
        "plt.xlabel('Percentage');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcVVmov_na8a"
      },
      "source": [
        "It appears that close to 10% of respondents are employed part time or as freelancers.\n",
        "\n",
        "**Exercise**: Add a new column `EmploymentType` containing the values `Enthusiast` (student or not employed but looking for work), `Professional` (employed full-time, part-time or freelancing), and `Other` (not employed or retired). For each of the graphs that follow, show a comparison between `Enthusiast` and `Professional`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq8qRAbina8a"
      },
      "source": [
        "The `DevType` field contains information about the roles held by respondents. Since the question allows multiple answers, the column contains lists of values separated by a semi-colon `;`, making it a bit harder to analyze directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwLD68qwna8a"
      },
      "outputs": [],
      "source": [
        "schema.DevType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j8Bg1Lhna8a"
      },
      "outputs": [],
      "source": [
        "survey_df.DevType.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAknEJTGna8a"
      },
      "source": [
        "Let's define a helper function that turns a column containing lists of values (like `survey_df.DevType`) into a data frame with one column for each possible option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icqhXXjKna8a"
      },
      "outputs": [],
      "source": [
        "def split_multicolumn(col_series):\n",
        "    result_df = col_series.to_frame()\n",
        "    options = []\n",
        "    # Iterate over the column\n",
        "    for idx, value  in col_series[col_series.notnull()].iteritems():\n",
        "        # Break each value into list of options\n",
        "        for option in value.split(';'):\n",
        "            # Add the option as a column to result\n",
        "            if not option in result_df.columns:\n",
        "                options.append(option)\n",
        "                result_df[option] = False\n",
        "            # Mark the value in the option column as True\n",
        "            result_df.at[idx, option] = True\n",
        "    return result_df[options]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjQIvpAHna8a"
      },
      "outputs": [],
      "source": [
        "dev_type_df = split_multicolumn(survey_df.DevType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VhOmQeRna8a"
      },
      "outputs": [],
      "source": [
        "dev_type_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dV5Q5X2na8a"
      },
      "source": [
        "The `dev_type_df` has one column for each option that can be selected as a response. If a respondent has chosen an option, the corresponding column's value is `True`. Otherwise, it is `False`.\n",
        "\n",
        "We can now use the column-wise totals to identify the most common roles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0uFOMoNna8b"
      },
      "outputs": [],
      "source": [
        "dev_type_totals = dev_type_df.sum().sort_values(ascending=False)\n",
        "dev_type_totals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvJS1pimna8b"
      },
      "source": [
        "As one might expect, the most common roles include \"Developer\" in the name. \n",
        "\n",
        "**Exercises**: \n",
        "\n",
        "* Can you figure out what percentage of respondents work in roles related to data science? \n",
        "* Which positions have the highest percentage of women?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QavTVCDEna8b"
      },
      "source": [
        "We've only explored a handful of columns from the 20 columns that we selected. Explore and visualize the remaining columns using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVyNmH7ana8b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cugIXCIena8b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUeC_Y-xna8b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7HvY2Bwna8b"
      },
      "source": [
        "Let's save and upload our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0t6axEdna8b"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptPzLHWEna8b"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdKiacEYna8b"
      },
      "source": [
        "## Asking and Answering Questions\n",
        "\n",
        "We've already gained several insights about the respondents and the programming community by exploring individual columns of the dataset. Let's ask some specific questions and try to answer them using data frame operations and visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcqwRUh3na8b"
      },
      "source": [
        "#### Q: What are the most popular programming languages in 2020? \n",
        "\n",
        "To answer, this we can use the `LanguageWorkedWith` column. Similar to `DevType`, respondents were allowed to choose multiple options here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjsVbblNna8b"
      },
      "outputs": [],
      "source": [
        "survey_df.LanguageWorkedWith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5VxACzIna8b"
      },
      "source": [
        "First, we'll split this column into a data frame containing a column of each language listed in the options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tklrs_0na8b"
      },
      "outputs": [],
      "source": [
        "languages_worked_df = split_multicolumn(survey_df.LanguageWorkedWith)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzbKBMiDna8b"
      },
      "outputs": [],
      "source": [
        "languages_worked_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YrKJW_Ona8b"
      },
      "source": [
        "It appears that a total of 25 languages were included among the options. Let's aggregate these to identify the percentage of respondents who selected each language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSV8MqYyna8b"
      },
      "outputs": [],
      "source": [
        "languages_worked_percentages = languages_worked_df.mean().sort_values(ascending=False) * 100\n",
        "languages_worked_percentages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QLIxLqmna8b"
      },
      "source": [
        "We can plot this information using a horizontal bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNzDIyK3na8b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "sns.barplot(x=languages_worked_percentages, y=languages_worked_percentages.index)\n",
        "plt.title(\"Languages used in the past year\");\n",
        "plt.xlabel('count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMNFx32bna8b"
      },
      "source": [
        "Perhaps unsurprisingly, Javascript & HTML/CSS comes out at the top as web development is one of today's most sought skills. It also happens to be one of the easiest to get started. SQL is necessary for working with relational databases, so it's no surprise that most programmers work with SQL regularly. Python seems to be the popular choice for other forms of development, beating out Java, which was the industry standard for server & application development for over two decades.\n",
        "\n",
        "**Exercises**:\n",
        "\n",
        "* What are the most common languages used by students? How does the list compare with the most common languages used by professional developers?\n",
        "* What are the most common languages among respondents who do not describe themselves as \"Developer, front-end\"?\n",
        "* What are the most common languages among respondents who work in fields related to data science?\n",
        "* What are the most common languages used by developers older than 35 years of age? \n",
        "* What are the most common languages used by developers in your home country?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HW57wvGna8b"
      },
      "source": [
        "#### Q: Which languages are the most people interested to learn over the next year?\n",
        "\n",
        "For this, we can use the `LanguageDesireNextYear` column, with similar processing as the previous one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJaRN-Nzna8b"
      },
      "outputs": [],
      "source": [
        "languages_interested_df = split_multicolumn(survey_df.LanguageDesireNextYear)\n",
        "languages_interested_percentages = languages_interested_df.mean().sort_values(ascending=False) * 100\n",
        "languages_interested_percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "fIVMUHVTna8b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "sns.barplot(x=languages_interested_percentages, y=languages_interested_percentages.index)\n",
        "plt.title(\"Languages people are intersted in learning over the next year\");\n",
        "plt.xlabel('count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRTo5JNEna8b"
      },
      "source": [
        "Once again, it's not surprising that Python is the language most people are interested in learning - since it is an easy-to-learn general-purpose programming language well suited for a variety of domains: application development, numerical computing, data analysis, machine learning, big data, cloud automation, web scraping, scripting, etc. We're using Python for this very analysis, so we're in good company!\n",
        "\n",
        "**Exercises**: Repeat the exercises from the previous question, replacing \"most common languages\" with \"languages people are interested in learning/using.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPZZVNIna8c"
      },
      "source": [
        "#### Q:  Which are the most loved languages, i.e., a high percentage of people who have used the language want to continue learning & using it over the next year?\n",
        "\n",
        "While this question may seem tricky at first, it's straightforward to solve using Pandas array operations. Here's what we can do:\n",
        "\n",
        "- Create a new data frame `languages_loved_df` that contains a `True` value for a language only if the corresponding values in `languages_worked_df` and `languages_interested_df` are both `True`\n",
        "- Take the column-wise sum of `languages_loved_df` and divide it by the column-wise sum of `languages_worked_df` to get the percentage of respondents who \"love\" the language\n",
        "- Sort the results in decreasing order and plot a horizontal bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_tKL7bbna8c"
      },
      "outputs": [],
      "source": [
        "languages_loved_df = languages_worked_df & languages_interested_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4ihLJXUna8c"
      },
      "outputs": [],
      "source": [
        "languages_loved_percentages = (languages_loved_df.sum() * 100/ languages_worked_df.sum()).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPk0RX2Ena8c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "sns.barplot(x=languages_loved_percentages, y=languages_loved_percentages.index)\n",
        "plt.title(\"Most loved languages\");\n",
        "plt.xlabel('count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19r1uNl3na8c"
      },
      "source": [
        "[Rust](https://www.rust-lang.org) has been StackOverflow's most-loved language for [four years in a row](https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/). The second most-loved language is TypeScript, a popular alternative to JavaScript for web development.\n",
        "\n",
        "Python features at number 3, despite already being one of the most widely-used languages in the world. Python has a solid foundation, is easy to learn & use, has a large ecosystem of domain-specific libraries, and a massive worldwide community.\n",
        "\n",
        "**Exercises:** What are the most dreaded languages, i.e., languages which people have used in the past year but do not want to learn/use over the next year. Hint: `~languages_interested_df`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWNwc1ZAna8c"
      },
      "source": [
        "#### Q: In which countries do developers work the highest number of hours per week? Consider countries with more than 250 responses only.\n",
        "\n",
        "To answer this question, we'll need to use the `groupby` data frame method to aggregate the rows for each country. We'll also need to filter the results to only include the countries with more than 250 respondents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i3l6Nxcna8c"
      },
      "outputs": [],
      "source": [
        "countries_df = survey_df.groupby('Country')[['WorkWeekHrs']].mean().sort_values('WorkWeekHrs', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6kg1sGGna8c"
      },
      "outputs": [],
      "source": [
        "high_response_countries_df = countries_df.loc[survey_df.Country.value_counts() > 250].head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73zeNFR5na8c"
      },
      "outputs": [],
      "source": [
        "high_response_countries_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK9GZIRfna8c"
      },
      "source": [
        "The Asian countries like Iran, China, and Israel have the highest working hours, followed by the United States. However, there isn't too much variation overall, and the average working hours seem to be around 40 hours per week.\n",
        "\n",
        "**Exercises:**\n",
        "\n",
        "* How do the average work hours compare across continents? You may find this list of [countries in each continent](https://hub.jovian.ml/wp-content/uploads/2020/09/countries.csv) useful.\n",
        "* Which role has the highest average number of hours worked per week? Which one has the lowest?\n",
        "* How do the hours worked compare between freelancers and developers working full-time?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0dWlSUpna8c"
      },
      "source": [
        "#### Q: How important is it to start young to build a career in programming?\n",
        "\n",
        "Let's create a scatter plot of `Age` vs. `YearsCodePro` (i.e., years of coding experience) to answer this question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHETPJsena8c"
      },
      "outputs": [],
      "source": [
        "schema.YearsCodePro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ7ewsxina8c"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='Age', y='YearsCodePro', hue='Hobbyist', data=survey_df)\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Years of professional coding experience\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_mo7BA9na8c"
      },
      "source": [
        "You can see points all over the graph, which indicates that you can **start programming professionally at any age**. Many people who have been coding for several decades professionally also seem to enjoy it as a hobby.\n",
        "\n",
        "We can also view the distribution of the `Age1stCode` column to see when the respondents tried programming for the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpCbc4WBna8c"
      },
      "outputs": [],
      "source": [
        "plt.title(schema.Age1stCode)\n",
        "sns.histplot(x=survey_df.Age1stCode, bins=30, kde=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNhlNgtCna8c"
      },
      "source": [
        "As you might expect, most people seem to have had some exposure to programming before the age of 40. However, but there are people of all ages and walks of life learning to code.\n",
        "\n",
        "**Exercises**:\n",
        "\n",
        "* How does programming experience change opinions & preferences? Repeat the entire analysis while comparing the responses of people who have more than ten years of professional programming experience vs. those who don't. Do you see any interesting trends?\n",
        "* Compare the years of professional coding experience across different genders. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Tf8Yq6na8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU0SiPjDna8c"
      },
      "source": [
        "Hopefully, you are already thinking of many more questions you'd like to answer using this data. Use the empty cells below to ask and answer more questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v31x5pAmna8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWd3qjMbna8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KREcfZpgna8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8s_gqSpna8c"
      },
      "source": [
        "Let's save and commit our work before continuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Mg_Nwpna8c"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm00w3DRna8c"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VgmY-hVna8c"
      },
      "source": [
        "## Inferences and Conclusions\n",
        "\n",
        "We've drawn many inferences from the survey. Here's a summary of a few of them:\n",
        "\n",
        "- Based on the survey respondents' demographics, we can infer that the survey is somewhat representative of the overall programming community. However, it has fewer responses from programmers in non-English-speaking countries and women & non-binary genders.\n",
        "\n",
        "- The programming community is not as diverse as it can be. Although things are improving, we should make more efforts to support & encourage underrepresented communities, whether in terms of age, country, race, gender, or otherwise.\n",
        "\n",
        "\n",
        "- Although most programmers hold a college degree, a reasonably large percentage did not have computer science as their college major. Hence, a computer science degree isn't compulsory for learning to code or building a career in programming.\n",
        "\n",
        "- A significant percentage of programmers either work part-time or as freelancers, which can be a great way to break into the field, especially when you're just getting started.\n",
        "\n",
        "- Javascript & HTML/CSS are the most used programming languages in 2020, closely followed by SQL & Python.\n",
        "\n",
        "- Python is the language most people are interested in learning - since it is an easy-to-learn general-purpose programming language well suited for various domains.\n",
        "\n",
        "- Rust and TypeScript are the most \"loved\" languages in 2020, both of which have small but fast-growing communities. Python is a close third, despite already being a widely used language.\n",
        "\n",
        "- Programmers worldwide seem to be working for around 40 hours a week on average, with slight variations by country.\n",
        "\n",
        "- You can learn and start programming professionally at any age. You're likely to have a long and fulfilling career if you also enjoy programming as a hobby.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "640xk-yqna8c"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "There's a wealth of information to be discovered using the survey, and we've barely scratched the surface. Here are some ideas for further exploration:\n",
        "\n",
        "- Repeat the analysis for different age groups & genders, and compare the results\n",
        "- Pick a different set of columns (we chose 20 out of 65) to analyze other facets of the data\n",
        "- Prepare an analysis focusing on diversity - and identify areas where underrepresented communities are at par with the majority (e.g., education) and where they aren't (e.g., salaries)\n",
        "- Compare the results of this year's survey with the previous years and identify interesting trends\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qlZt11xna8d"
      },
      "source": [
        "## References and Future Work\n",
        "\n",
        "Check out the following resources to learn more about the dataset and tools used in this notebook:\n",
        "\n",
        "- Stack Overflow Developer Survey: https://insights.stackoverflow.com/survey\n",
        "- Pandas user guide: https://pandas.pydata.org/docs/user_guide/index.html\n",
        "- Matplotlib user guide: https://matplotlib.org/3.3.1/users/index.html\n",
        "- Seaborn user guide & tutorial: https://seaborn.pydata.org/tutorial.html\n",
        "- `opendatasets` Python library: https://github.com/JovianML/opendatasets\n",
        "\n",
        "As a next step, you can try out a project on another dataset of your choice: https://jovian.ml/aakashns/zerotopandas-course-project-starter ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9QsWiuUna8d"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsyeLrOQna8d"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtYizByxna8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}